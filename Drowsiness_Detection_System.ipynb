{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Drowsiness Detection System",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivendra200225raigithub/Drowsiness-detection-system/blob/main/Drowsiness_Detection_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'drowsiness-prediction-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F857148%2F1461668%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240820%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240820T194924Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6087083476efa6e7b8937d84b13bf2086912490f5f4f3cf9d7b5cb77e42ce208bf29f40a43e90f1aaa25d22632ab8c9263add2bf4464ca1f41491024396bb4cf171351eb0308aae2c9208fe2f6455847b2fd6c61e7b1eccddaf2406dea158a2bb2597bfbf419754cbe8a678bbce617a05485e60cc9f732bd28e24be5cb07bb79cbe5e0959f3efb2dae3e1bbfbe5ec35c59aedfd82eaf18357ad0d3a86d5c48fa7dd335ac9a3d23939a1008eef3191fb5ccce016b2dbeed3865fe52a34034798c804af881fff4f3077e3b552f576246a8e03967516c9e24c70682a7c72cf3ad6041f762da56bc93cca560a057e0799375977d594bab23484724e54fca4f43028a,prediction-images:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F839168%2F2935731%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240820%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240820T194924Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2a8e12a34d0db6bca8d442ef5ff274ec5dbf4b5c82602f3674edb69eebc61e6f24fdcb887e6be124cd718fe7f32103cf5a556353084363a65deac43fe6d78a347d8a24613545d58f3c66f85299473ba82cefcda28bf28838c4b828dd7fb7b9c599a64e340cb2fcb759e1ea007378a08083d48d698ef969cd5d0ae33bc72aa6c79044dc5cc89f0a16d2e4f4314f1269f39f585e1789cdf5d3043c6fcdddf25192d2dfe4a0183448e342da7a2f0baca460cb8fa25ba44183e7da3a920a49dc5b08766c1940a84c28bc626b53306785256327cc447d384708a1942b993cfa3bde81a042c11a58a69ed902dd0fc46ead77c17432cc93e95ba1d2816f519dfb2d0051'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WURTwrFcVli4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drowsiness Detection System\n",
        "\n",
        "- Drowsy Driving is a deadly combination of driving and sleepiness.\n",
        "\n",
        "- The number of road accidents due to Drowsy Driving is increasing at an alarming rate worldwide.\n",
        "\n",
        "- Not having a proper sleep is the main reason behind drowsiness while driving. However, other reasons like sleep disorders, medication, alcohol consumption, or driving during night shifts can also cause drowsiness while driving.\n"
      ],
      "metadata": {
        "id": "tthC-ZyxVli-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:4d03656c-4680-41f0-9e9d-18ebcccac398.png)"
      ],
      "metadata": {
        "id": "B7zt-vBVVljA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data and libraries"
      ],
      "metadata": {
        "id": "VYB8_EXNVljB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "\n",
        "mp_facemesh = mp.solutions.face_mesh\n",
        "mp_drawing  = mp.solutions.drawing_utils\n",
        "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xFw2LMhLPgE4",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:20:42.373004Z",
          "iopub.execute_input": "2022-11-13T20:20:42.373637Z",
          "iopub.status.idle": "2022-11-13T20:20:56.29781Z",
          "shell.execute_reply.started": "2022-11-13T20:20:42.373548Z",
          "shell.execute_reply": "2022-11-13T20:20:56.296748Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./Fatigue Subjects')\n",
        "os.makedirs('./Active Subjects')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "vKOwYE7YPR-k",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:20:56.301206Z",
          "iopub.execute_input": "2022-11-13T20:20:56.302105Z",
          "iopub.status.idle": "2022-11-13T20:20:56.307715Z",
          "shell.execute_reply.started": "2022-11-13T20:20:56.302065Z",
          "shell.execute_reply": "2022-11-13T20:20:56.306846Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image preprocessing :\n",
        "### our preprocessing will include\n",
        "- Detecting faces from images\n",
        "- Drawing landmarks on our images to increase performance\n",
        "- Resizing our images\n",
        "- LabelEncoding\n",
        "- Image Augmantation"
      ],
      "metadata": {
        "id": "VXS_ajkRVljC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Landmarks :\n",
        "We will use mediapipe to draw landmarks on our images after detecting faces and croping them"
      ],
      "metadata": {
        "id": "HgcpIrH1VljD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Landmark points corresponding to left eye\n",
        "all_left_eye_idxs = list(mp_facemesh.FACEMESH_LEFT_EYE)\n",
        "# flatten and remove duplicates\n",
        "all_left_eye_idxs = set(np.ravel(all_left_eye_idxs))\n",
        "\n",
        "# Landmark points corresponding to right eye\n",
        "all_right_eye_idxs = list(mp_facemesh.FACEMESH_RIGHT_EYE)\n",
        "all_right_eye_idxs = set(np.ravel(all_right_eye_idxs))\n",
        "\n",
        "# Combined for plotting - Landmark points for both eye\n",
        "all_idxs = all_left_eye_idxs.union(all_right_eye_idxs)\n",
        "\n",
        "# The chosen 12 points:   P1,  P2,  P3,  P4,  P5,  P6\n",
        "chosen_left_eye_idxs  = [362, 385, 387, 263, 373, 380]\n",
        "chosen_right_eye_idxs = [33,  160, 158, 133, 153, 144]\n",
        "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs"
      ],
      "metadata": {
        "id": "KSgkzCv5cX4p",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:20:56.309557Z",
          "iopub.execute_input": "2022-11-13T20:20:56.310001Z",
          "iopub.status.idle": "2022-11-13T20:20:56.318929Z",
          "shell.execute_reply.started": "2022-11-13T20:20:56.309967Z",
          "shell.execute_reply": "2022-11-13T20:20:56.318022Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE=145\n",
        "i=0\n",
        "def draw(\n",
        "    *,n=i,\n",
        "    img_dt,cat,\n",
        "    img_eye_lmks=None,\n",
        "    img_eye_lmks_chosen=None,\n",
        "    face_landmarks=None,\n",
        "    ts_thickness=1,\n",
        "    ts_circle_radius=2,\n",
        "    lmk_circle_radius=3,\n",
        "    name=\"1\",\n",
        "):\n",
        "    # For plotting Face Tessellation\n",
        "    image_drawing_tool = img_dt\n",
        "\n",
        "     # For plotting all eye landmarks\n",
        "    image_eye_lmks = img_dt.copy() if img_eye_lmks is None else img_eye_lmks\n",
        "\n",
        "    # For plotting chosen eye landmarks\n",
        "    img_eye_lmks_chosen = img_dt.copy() if img_eye_lmks_chosen is None else img_eye_lmks_chosen\n",
        "\n",
        "    # Initializing drawing utilities for plotting face mesh tessellation\n",
        "    connections_drawing_spec = mp_drawing.DrawingSpec(\n",
        "        thickness=ts_thickness,\n",
        "        circle_radius=ts_circle_radius,\n",
        "        color=(255, 255, 255)\n",
        "    )\n",
        "\n",
        "\n",
        "    # Draw landmarks on face using the drawing utilities.\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image=image_drawing_tool,\n",
        "        landmark_list=face_landmarks,\n",
        "        connections=mp_facemesh.FACEMESH_TESSELATION,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=connections_drawing_spec,\n",
        "    )\n",
        "\n",
        "    # Get the object which holds the x, y, and z coordinates for each landmark\n",
        "    landmarks = face_landmarks.landmark\n",
        "\n",
        "    # Iterate over all landmarks.\n",
        "    # If the landmark_idx is present in either all_idxs or all_chosen_idxs,\n",
        "    # get the denormalized coordinates and plot circles at those coordinates.\n",
        "\n",
        "    for landmark_idx, landmark in enumerate(landmarks):\n",
        "        if landmark_idx in all_idxs:\n",
        "            pred_cord = denormalize_coordinates(landmark.x,\n",
        "                                                landmark.y,\n",
        "                                                imgW, imgH)\n",
        "            cv2.circle(image_eye_lmks,\n",
        "                       pred_cord,\n",
        "                       lmk_circle_radius,\n",
        "                       (255, 255, 255),\n",
        "                       -1\n",
        "                       )\n",
        "\n",
        "        if landmark_idx in all_chosen_idxs:\n",
        "            pred_cord = denormalize_coordinates(landmark.x,\n",
        "                                                landmark.y,\n",
        "                                                imgW, imgH)\n",
        "            cv2.circle(img_eye_lmks_chosen,\n",
        "                       pred_cord,\n",
        "                       lmk_circle_radius,\n",
        "                       (255, 255, 255),\n",
        "                       -1\n",
        "                       )\n",
        "\n",
        "    if cat=='Fatigue Subjects':\n",
        "        cv2.imwrite(str('./Fatigue Subjects/'+str(n)+'.jpg'), image_drawing_tool)\n",
        "    else:\n",
        "        cv2.imwrite(str('./Active Subjects/'+str(n)+'.jpg'), image_drawing_tool)\n",
        "\n",
        "    resized_array = cv2.resize(image_drawing_tool, (IMG_SIZE, IMG_SIZE))\n",
        "    return resized_array"
      ],
      "metadata": {
        "id": "Dm3ZA9ypcXv5",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:20:56.321736Z",
          "iopub.execute_input": "2022-11-13T20:20:56.322126Z",
          "iopub.status.idle": "2022-11-13T20:20:56.334306Z",
          "shell.execute_reply.started": "2022-11-13T20:20:56.322083Z",
          "shell.execute_reply": "2022-11-13T20:20:56.333021Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgH, imgW, _=0,0,0\n",
        "def landmarks(image,category,i):\n",
        "    resized_array=[]\n",
        "    IMG_SIZE = 145\n",
        "    image = np.ascontiguousarray(image)\n",
        "    imgH, imgW, _ = image.shape\n",
        "\n",
        "     # Running inference using static_image_mode\n",
        "    with mp_facemesh.FaceMesh(\n",
        "        static_image_mode=True,         # Default=False\n",
        "        max_num_faces=1,                # Default=1\n",
        "        refine_landmarks=False,         # Default=False\n",
        "        min_detection_confidence=0.5,   # Default=0.5\n",
        "        min_tracking_confidence= 0.5,) as face_mesh:\n",
        "\n",
        "        results = face_mesh.process(image)\n",
        "\n",
        "        # If detections are available.\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_id, face_landmarks in enumerate(results.multi_face_landmarks):\n",
        "                resized_array= draw(img_dt=image.copy(), cat=category, n=i,face_landmarks=face_landmarks)\n",
        "    return resized_array"
      ],
      "metadata": {
        "id": "b5ln3QUWerf5",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:20:56.335889Z",
          "iopub.execute_input": "2022-11-13T20:20:56.336259Z",
          "iopub.status.idle": "2022-11-13T20:20:56.346426Z",
          "shell.execute_reply.started": "2022-11-13T20:20:56.336224Z",
          "shell.execute_reply": "2022-11-13T20:20:56.345451Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_for_yawn(direc=\"../input/drowsiness-prediction-dataset/0 FaceImages\", face_cas_path=\"../input/prediction-images/haarcascade_frontalface_default.xml\"):\n",
        "    yaw_no=[]\n",
        "    i=1\n",
        "    IMG_SIZE = 145\n",
        "    categories = [\"Fatigue Subjects\", \"Active Subjects\"]\n",
        "    for category in categories:\n",
        "        path_link = os.path.join(direc, category)\n",
        "        class_num1 = categories.index(category)\n",
        "        print(class_num1)\n",
        "        for image in os.listdir(path_link):\n",
        "            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n",
        "            face_cascade = cv2.CascadeClassifier(face_cas_path)\n",
        "            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n",
        "            for (x, y, w, h) in faces:\n",
        "                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "                roi_color = img[y:y+h, x:x+w]\n",
        "                land_face_array=landmarks(roi_color,category,i)\n",
        "                yaw_no.append([land_face_array, class_num1])\n",
        "                i=i+1\n",
        "    return yaw_no\n",
        "yawn_no_yawn = face_for_yawn()"
      ],
      "metadata": {
        "id": "Dck2gCV-PR-p",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:20:56.347957Z",
          "iopub.execute_input": "2022-11-13T20:20:56.348332Z",
          "iopub.status.idle": "2022-11-13T20:56:33.798478Z",
          "shell.execute_reply.started": "2022-11-13T20:20:56.348297Z",
          "shell.execute_reply": "2022-11-13T20:56:33.797404Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = r'./Active Subjects'\n",
        "print(\"Number of Active images :\")\n",
        "print(len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))"
      ],
      "metadata": {
        "id": "WEwfoTWB98w0",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:56:33.800383Z",
          "iopub.execute_input": "2022-11-13T20:56:33.800794Z",
          "iopub.status.idle": "2022-11-13T20:56:33.830149Z",
          "shell.execute_reply.started": "2022-11-13T20:56:33.800747Z",
          "shell.execute_reply": "2022-11-13T20:56:33.829108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = r'./Fatigue Subjects'\n",
        "print(\"Number of Fatigue images :\")\n",
        "print(len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))]))"
      ],
      "metadata": {
        "id": "E1tHP_FL98nF",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:56:33.831488Z",
          "iopub.execute_input": "2022-11-13T20:56:33.832102Z",
          "iopub.status.idle": "2022-11-13T20:56:33.859748Z",
          "shell.execute_reply.started": "2022-11-13T20:56:33.832067Z",
          "shell.execute_reply": "2022-11-13T20:56:33.85874Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our images will be like this:"
      ],
      "metadata": {
        "id": "2IHtJrIIVljG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"Fatigue Subjects\", \"Active Subjects\"]\n",
        "for category in categories:\n",
        "  for idx, img in enumerate(os.listdir(f'./{category}')):\n",
        "      if idx > 5:\n",
        "        break\n",
        "      img_file = cv2.imread(f'./{category}/{img}')\n",
        "      plt.imshow(img_file)\n",
        "      plt.show()\n",
        "      plt.close()"
      ],
      "metadata": {
        "id": "UCgijSq_zuW7",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:56:33.861064Z",
          "iopub.execute_input": "2022-11-13T20:56:33.861471Z",
          "iopub.status.idle": "2022-11-13T20:56:36.743482Z",
          "shell.execute_reply.started": "2022-11-13T20:56:33.861437Z",
          "shell.execute_reply": "2022-11-13T20:56:36.742562Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resizing images"
      ],
      "metadata": {
        "id": "m2s2R2fQVljG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "def face_for_yawn(direc=\"./\"):\n",
        "    yaw_no=[]\n",
        "    i=1\n",
        "    IMG_SIZE = 145\n",
        "    categories = [\"Fatigue Subjects\", \"Active Subjects\"]\n",
        "    for category in categories:\n",
        "        path_link = os.path.join(direc, category)\n",
        "        class_num1 = categories.index(category)\n",
        "        print(class_num1)\n",
        "        for image in os.listdir(path_link):\n",
        "            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n",
        "            resized_array = cv2.resize(image_array, (IMG_SIZE, IMG_SIZE))\n",
        "            yaw_no.append([resized_array, class_num1])\n",
        "                #print('image face number '+str(i))\n",
        "                #i=i+1\n",
        "    return yaw_no\n",
        "yawn_no_yawn = face_for_yawn()"
      ],
      "metadata": {
        "id": "0tHKdRF8PR-r",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:56:36.747227Z",
          "iopub.execute_input": "2022-11-13T20:56:36.747898Z",
          "iopub.status.idle": "2022-11-13T20:57:07.961911Z",
          "shell.execute_reply.started": "2022-11-13T20:56:36.747859Z",
          "shell.execute_reply": "2022-11-13T20:57:07.960939Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## separate label and features"
      ],
      "metadata": {
        "id": "3isUEA8XPR-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for feature, label in yawn_no_yawn:\n",
        "    X.append(feature)\n",
        "    y.append(label)"
      ],
      "metadata": {
        "id": "mVRgroJEPR-s",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:07.964606Z",
          "iopub.execute_input": "2022-11-13T20:57:07.965022Z",
          "iopub.status.idle": "2022-11-13T20:57:07.972211Z",
          "shell.execute_reply.started": "2022-11-13T20:57:07.964984Z",
          "shell.execute_reply": "2022-11-13T20:57:07.971041Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape the array"
      ],
      "metadata": {
        "id": "kOWjQcuaPR-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "X = X.reshape(-1, 145, 145, 3)"
      ],
      "metadata": {
        "id": "vDpba9fEPR-s",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:07.973818Z",
          "iopub.execute_input": "2022-11-13T20:57:07.974463Z",
          "iopub.status.idle": "2022-11-13T20:57:08.127081Z",
          "shell.execute_reply.started": "2022-11-13T20:57:07.974427Z",
          "shell.execute_reply": "2022-11-13T20:57:08.126074Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LabelEncoder"
      ],
      "metadata": {
        "id": "9rOouR4tPR-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_bin = LabelEncoder()\n",
        "y = label_bin.fit_transform(y)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "uR7V1r8iPR-s",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:08.128377Z",
          "iopub.execute_input": "2022-11-13T20:57:08.128757Z",
          "iopub.status.idle": "2022-11-13T20:57:08.587834Z",
          "shell.execute_reply.started": "2022-11-13T20:57:08.128713Z",
          "shell.execute_reply": "2022-11-13T20:57:08.586894Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting"
      ],
      "metadata": {
        "id": "qGxNWmYwPR-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "seed = 42\n",
        "test_size = 0.20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)"
      ],
      "metadata": {
        "id": "HCYAjIgTPR-t",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:08.589079Z",
          "iopub.execute_input": "2022-11-13T20:57:08.591484Z",
          "iopub.status.idle": "2022-11-13T20:57:08.782708Z",
          "shell.execute_reply.started": "2022-11-13T20:57:08.591441Z",
          "shell.execute_reply": "2022-11-13T20:57:08.781547Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "id": "5umUs7eMPR-t",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:08.784636Z",
          "iopub.execute_input": "2022-11-13T20:57:08.785108Z",
          "iopub.status.idle": "2022-11-13T20:57:08.795124Z",
          "shell.execute_reply.started": "2022-11-13T20:57:08.785065Z",
          "shell.execute_reply": "2022-11-13T20:57:08.793858Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "6bzaKKbTzpmQ",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:08.796702Z",
          "iopub.execute_input": "2022-11-13T20:57:08.797634Z",
          "iopub.status.idle": "2022-11-13T20:57:08.808069Z",
          "shell.execute_reply.started": "2022-11-13T20:57:08.797591Z",
          "shell.execute_reply": "2022-11-13T20:57:08.806641Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import some dependencies"
      ],
      "metadata": {
        "id": "JwaNP1OePR-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "sTgEHYiGPR-u",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:08.809961Z",
          "iopub.execute_input": "2022-11-13T20:57:08.810571Z",
          "iopub.status.idle": "2022-11-13T20:57:13.674313Z",
          "shell.execute_reply.started": "2022-11-13T20:57:08.81053Z",
          "shell.execute_reply": "2022-11-13T20:57:13.673298Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "LOdCyv1APR-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\n",
        "test_generator = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)\n",
        "test_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)"
      ],
      "metadata": {
        "id": "B88AD-JVPR-v",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:13.675926Z",
          "iopub.execute_input": "2022-11-13T20:57:13.6766Z",
          "iopub.status.idle": "2022-11-13T20:57:14.307053Z",
          "shell.execute_reply.started": "2022-11-13T20:57:13.676561Z",
          "shell.execute_reply": "2022-11-13T20:57:14.306009Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "griSUS_zPR-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Elsafty 1\n",
        "from keras.layers import BatchNormalization\n",
        "model = tf.keras.models.Sequential()\n",
        "# Note the input shape is the desired size of the image 145 x 145 with 3 bytes color\n",
        "# This is the first convolution\n",
        "model.add(Conv2D(16, 3, activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "tf.keras.layers.Dropout(0.1)\n",
        "# The second convolution\n",
        "model.add(Conv2D(32, 5, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "tf.keras.layers.Dropout(0.1)\n",
        "# The third convolution\n",
        "model.add(Conv2D(64, 10, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "tf.keras.layers.Dropout(0.1)\n",
        "# The fourth convolution\n",
        "model.add(Conv2D(128, 12, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Flatten the results to feed into a DNN\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# Only 1 output neuron.\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "m_cVcm3mWNBJ",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:14.308573Z",
          "iopub.execute_input": "2022-11-13T20:57:14.309207Z",
          "iopub.status.idle": "2022-11-13T20:57:17.104782Z",
          "shell.execute_reply.started": "2022-11-13T20:57:14.309168Z",
          "shell.execute_reply": "2022-11-13T20:57:17.103808Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=70, validation_data=test_generator)"
      ],
      "metadata": {
        "id": "5XJ5vd7BoYLz",
        "execution": {
          "iopub.status.busy": "2022-11-13T20:57:17.106197Z",
          "iopub.execute_input": "2022-11-13T20:57:17.10698Z",
          "iopub.status.idle": "2022-11-13T21:29:36.678032Z",
          "shell.execute_reply.started": "2022-11-13T20:57:17.106942Z",
          "shell.execute_reply": "2022-11-13T21:29:36.67709Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, \"b\", label=\"trainning loss\")\n",
        "plt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r3jV3Uo3GC5f",
        "execution": {
          "iopub.status.busy": "2022-11-13T21:35:49.088311Z",
          "iopub.execute_input": "2022-11-13T21:35:49.088692Z",
          "iopub.status.idle": "2022-11-13T21:35:49.496071Z",
          "shell.execute_reply.started": "2022-11-13T21:35:49.088645Z",
          "shell.execute_reply": "2022-11-13T21:35:49.495186Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can evaluate or predict on a dataset.\n",
        "print(\"Evaluate\")\n",
        "result = model.evaluate(test_generator)\n",
        "dict(zip(model.metrics_names, result))"
      ],
      "metadata": {
        "id": "26AN1kQWPFjk",
        "execution": {
          "iopub.status.busy": "2022-11-13T21:36:11.42188Z",
          "iopub.execute_input": "2022-11-13T21:36:11.422802Z",
          "iopub.status.idle": "2022-11-13T21:36:11.919047Z",
          "shell.execute_reply.started": "2022-11-13T21:36:11.422766Z",
          "shell.execute_reply": "2022-11-13T21:36:11.918169Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')\n",
        "#model = tf.keras.models.load_model('my_model.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-13T21:42:56.150118Z",
          "iopub.execute_input": "2022-11-13T21:42:56.150498Z",
          "iopub.status.idle": "2022-11-13T21:42:56.238009Z",
          "shell.execute_reply.started": "2022-11-13T21:42:56.150464Z",
          "shell.execute_reply": "2022-11-13T21:42:56.237048Z"
        },
        "trusted": true,
        "id": "T-KYFQ9BVljJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "binary1 = np.array([[3427,252],[44,2331]])\n",
        "fig, ax = plot_confusion_matrix(conf_mat=binary1,show_absolute=True,\n",
        "                                show_normed=True,\n",
        "                                colorbar=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-14T15:51:00.382882Z",
          "iopub.execute_input": "2022-11-14T15:51:00.383251Z",
          "iopub.status.idle": "2022-11-14T15:51:00.602836Z",
          "shell.execute_reply.started": "2022-11-14T15:51:00.38322Z",
          "shell.execute_reply": "2022-11-14T15:51:00.601699Z"
        },
        "trusted": true,
        "id": "EBwrb6aCVljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing our CNN architecture"
      ],
      "metadata": {
        "id": "BGMt8wqWVljS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "from IPython.display import Image\n",
        "Image(\"model.png\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-13T21:43:40.291302Z",
          "iopub.execute_input": "2022-11-13T21:43:40.291662Z",
          "iopub.status.idle": "2022-11-13T21:43:41.338982Z",
          "shell.execute_reply.started": "2022-11-13T21:43:40.291631Z",
          "shell.execute_reply": "2022-11-13T21:43:41.337659Z"
        },
        "trusted": true,
        "id": "Yn3s-X50VljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "\n",
        "visualkeras.layered_view(model).show() # display using your system viewer\n",
        "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
        "visualkeras.layered_view(model, to_file='output.png').show() # write and show\n",
        "\n",
        "visualkeras.layered_view(model,legend=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-13T21:47:35.794178Z",
          "iopub.execute_input": "2022-11-13T21:47:35.79465Z",
          "iopub.status.idle": "2022-11-13T21:47:46.103251Z",
          "shell.execute_reply.started": "2022-11-13T21:47:35.79461Z",
          "shell.execute_reply": "2022-11-13T21:47:46.102191Z"
        },
        "trusted": true,
        "id": "pX7UGbdHVljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_sequential_ascii\n",
        "from keras_sequential_ascii import keras2ascii\n",
        "keras2ascii(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-13T21:44:08.778201Z",
          "iopub.execute_input": "2022-11-13T21:44:08.779327Z",
          "iopub.status.idle": "2022-11-13T21:44:20.495142Z",
          "shell.execute_reply.started": "2022-11-13T21:44:08.779288Z",
          "shell.execute_reply": "2022-11-13T21:44:20.493757Z"
        },
        "trusted": true,
        "id": "sWCDv2vSVljS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WcYSrdMVljT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}